{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/fj7dzt957rd1sg25bl4jv1b00000gn/T/ipykernel_14311/588057450.py:3: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, delimiter=';')\n",
      "/var/folders/xx/fj7dzt957rd1sg25bl4jv1b00000gn/T/ipykernel_14311/588057450.py:8: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data[col] = pd.to_datetime(data[col], errors='coerce')\n",
      "/var/folders/xx/fj7dzt957rd1sg25bl4jv1b00000gn/T/ipykernel_14311/588057450.py:8: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data[col] = pd.to_datetime(data[col], errors='coerce')\n",
      "/var/folders/xx/fj7dzt957rd1sg25bl4jv1b00000gn/T/ipykernel_14311/588057450.py:8: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data[col] = pd.to_datetime(data[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#cargar el dataset de dataset/s_alimentacion.csv que está 2 carpetas por encima de la actual\n",
    "file_path = '../../dataset/s_alimentacion.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "#convertir columnas de fechas a objetos datetime\n",
    "date_columns = ['FECHA_FACTURA', 'MAX_FECHA_COBRO', 'FECHA_CONTABILIZACION']\n",
    "for col in date_columns:\n",
    "    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "#extraer características de las fechas\n",
    "for col in date_columns:\n",
    "    data[col + '_YEAR'] = data[col].dt.year\n",
    "    data[col + '_MONTH'] = data[col].dt.month\n",
    "    data[col + '_DAY'] = data[col].dt.day\n",
    "    data[col + '_WEEKDAY'] = data[col].dt.weekday\n",
    "\n",
    "#eliminar las columnas originales de fecha si ya no son necesarias\n",
    "data.drop(columns=date_columns, inplace=True)\n",
    "\n",
    "columns_to_drop = ['EMPRESA', 'NUMERO_FACTURA', 'NUMERO_ASIENTO_BORRADOR', 'TIPO_FACTURA', 'DIARIO', 'IMPORTE_COBRADO_FRA', 'CUENTA_CONTABLE','NUM_EFECTOS_COBRADOS', 'NUM_EFECTOS_PARCIAL', 'NUM_EFECTOS_IMPAGADO', 'NUM_EFECTOS_FUERA_PLAZO', 'NUM_EFECTOS_PDTE_EN_PLAZO']\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "#convertir todas las entradas en las columnas categóricas a cadenas\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    data[column] = data[column].astype(str)\n",
    "\n",
    "#convertir columnas categóricas a variables numéricas\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "#recodificar las clases de la variable objetivo\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = label_encoder_y.fit_transform(data['CATEGORIA_FACTURA'])\n",
    "\n",
    "#separación de características y variable objetivo\n",
    "X = data.drop('CATEGORIA_FACTURA', axis=1)\n",
    "\n",
    "#sobremuestreo de la clase minoritaria utilizando SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "#división de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#estandarización de las características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#función para evaluar el rendimiento de los modelos\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return [name, accuracy, precision, recall, f1]\n",
    "\n",
    "#lista para almacenar resultados\n",
    "results = []\n",
    "\n",
    "#parámetros para GridSearchCV\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 20],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "#validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases sin smote\n",
      "CATEGORIA_FACTURA\n",
      " 1    160429\n",
      " 2     92679\n",
      "-1     24541\n",
      " 0     19118\n",
      "-2        55\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#mostramos cuantos registros hay de cada clase sin usar smote \n",
    "print(\"Clases sin smote\")\n",
    "print(data['CATEGORIA_FACTURA'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Árboles de Decisión\n",
    "dt = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=cv, refit=True, verbose=2)\n",
    "dt.fit(X_train, y_train)\n",
    "results.append(evaluate_model(\"Árboles de Decisión\", dt, X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=cv, refit=True, verbose=2)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = label_encoder_y.inverse_transform(rf.predict(X_test))\n",
    "results.append(evaluate_model(\"Random Forest\", rf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgboost = GridSearchCV(xgb.XGBClassifier(), param_grid_xgb, cv=cv, refit=True, verbose=2)\n",
    "xgboost.fit(X_train, y_train)\n",
    "y_pred_xgb = label_encoder_y.inverse_transform(xgboost.predict(X_test))\n",
    "\n",
    "results.append(evaluate_model(\"XGBoost\", xgboost, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors (K-NN)\n",
    "knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=cv, refit=True, verbose=2)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = label_encoder_y.inverse_transform(knn.predict(X_test))\n",
    "results.append(evaluate_model(\"K-Nearest Neighbors\", knn, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM con búsqueda de hiperparámetros\n",
    "svm = GridSearchCV(SVC(), param_grid_svm, cv=cv, refit=True, verbose=2)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = label_encoder_y.inverse_transform(svm.predict(X_test))\n",
    "results.append(evaluate_model(\"Support Vector Machine\", svm, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=10, gamma=0.1, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"\\nSupport Vector Machine:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(evaluate_model(\"Support Vector Machine\", svm, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('svm', SVC()),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "]\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking.fit(X_train, y_train)\n",
    "results.append(evaluate_model(\"Stacking\", stacking, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stacking: 1700\n",
    "\n",
    "svm: 463\n",
    "\n",
    "knn: 121\n",
    "\n",
    "xgb: 63\n",
    "\n",
    "rf: 193\n",
    "\n",
    "dt: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results, columns=[\"Modelo\", \"Exactitud\", \"Precisión\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Mostrar la tabla de resultados\n",
    "print(\"\\nTabla de comparación de modelos:\")\n",
    "print(results_df)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(12, 8))\n",
    "results_df.set_index(\"Modelo\").plot(kind='bar')\n",
    "plt.title('Comparación de rendimiento de modelos')\n",
    "plt.ylabel('Puntuación')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='best')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgboost = GridSearchCV(xgb.XGBClassifier(), param_grid_xgb, cv=cv, refit=True, verbose=2)\n",
    "xgboost.fit(X_train, y_train)\n",
    "y_pred_xgb = label_encoder_y.inverse_transform(xgboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir las matrices de confusión\n",
    "confusion_matrices = [\n",
    "    np.array([[16577, 0, 0, 13, 2], [1, 16470, 0, 4, 3], [1, 0, 16352, 352, 108], [4, 4, 54, 15328, 1280], [19, 0, 17, 1237, 15286]]),\n",
    "    np.array([[21016, 0, 3, 0], [0, 69590, 850, 21], [5, 1287, 67764, 755], [0, 60, 1156, 9985]]),\n",
    "    np.array([[18003, 0, 0, 0, 1], [0, 17816, 39, 1, 22], [0, 12, 17998, 53, 17], [0, 0, 153, 16955, 802], [0, 0, 66, 889, 16940]]),\n",
    "    np.array([[9685, 0, 0, 8, 17], [10, 8993, 54, 458, 162], [1, 45, 9626, 68, 15], [19, 548, 80, 8020, 946], [5, 238, 26, 976, 8259]]),\n",
    "    np.array([[31937, 0, 0, 0, 0], [2, 28028, 2658, 1060, 439], [2, 2319, 27865, 26, 1961], [0, 956, 23, 31161, 105], [0, 906, 3305, 124, 27552]])\n",
    "]\n",
    "\n",
    "# Crear una matriz de confusión unificada de tamaño adecuado\n",
    "# Encontrar el tamaño máximo de las matrices de confusión\n",
    "max_size = max(matrix.shape[0] for matrix in confusion_matrices)\n",
    "unified_confusion_matrix = np.zeros((max_size, max_size), dtype=int)\n",
    "\n",
    "# Sumar todas las matrices de confusión\n",
    "for matrix in confusion_matrices:\n",
    "    unified_confusion_matrix[:matrix.shape[0], :matrix.shape[1]] += matrix\n",
    "\n",
    "# Visualizar la matriz de confusión unificada\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(unified_confusion_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de confusión unificada')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gal_lua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
